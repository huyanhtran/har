{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e736f2-7cff-4f6c-9dfe-4a696e8e0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "# import keras\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "\n",
    "\n",
    "def merge_csi_label(csifile, labelfile, win_len=500, thrshd=0.6, step=50):\n",
    "    \"\"\"\n",
    "    Merge CSV files into a Numperrory Array  X,  csi amplitude feature\n",
    "    Returns Numpy Array X, Shape(Num, Win_Len, 90)\n",
    "    Args:\n",
    "        csifile  :  str, csv file containing CSI data\n",
    "        labelfile:  str, csv fiel with activity label \n",
    "        win_len  :  integer, window length\n",
    "        thrshd   :  float,  determine if an activity is strong enough inside a window\n",
    "        step     :  integer, sliding window by step\n",
    "    \"\"\"\n",
    "    activity = []\n",
    "    with open(labelfile, 'r') as labelf:\n",
    "        reader = csv.reader(labelf)\n",
    "        for line in reader:\n",
    "            label  = line[0]\n",
    "            if label == 'NoActivity':\n",
    "                activity.append(0)\n",
    "            else:\n",
    "                activity.append(1)\n",
    "    activity = np.array(activity)\n",
    "    csi = []\n",
    "    with open(csifile, 'r') as csif:\n",
    "        reader = csv.reader(csif)\n",
    "        for line in reader:\n",
    "            line_array = np.array([float(v) for v in line])\n",
    "            # extract the amplitude only\n",
    "            line_array = line_array[0:52]\n",
    "            csi.append(line_array[np.newaxis,...])\n",
    "    csi = np.concatenate(csi, axis=0)\n",
    "    assert(csi.shape[0] == activity.shape[0])\n",
    "    # screen the data with a window\n",
    "    index = 0\n",
    "    feature = []\n",
    "    while index + win_len <= csi.shape[0]:\n",
    "        cur_activity = activity[index:index+win_len]\n",
    "        if np.sum(cur_activity)  <  thrshd * win_len:\n",
    "            index += step\n",
    "            continue\n",
    "        cur_feature = np.zeros((1, win_len, 52))\n",
    "        cur_feature[0] = csi[index:index+win_len, :]\n",
    "        feature.append(cur_feature)\n",
    "        index += step\n",
    "    return np.concatenate(feature, axis=0)\n",
    "\n",
    "\n",
    "def extract_csi_by_label(raw_folder, label, labels, save=False, win_len=500, thrshd=0.6, step=50):\n",
    "    \"\"\"\n",
    "    Returns all the samples (X,y) of \"label\" in the entire dataset\n",
    "    Args:\n",
    "        raw_folder: The path of Dataset folder\n",
    "        label    : str, could be one of labels\n",
    "        labels   : list of str, ['lie down', 'fall', 'bend', 'run', 'sitdown', 'standup', 'walk']\n",
    "        save     : boolean, choose whether save the numpy array \n",
    "        win_len  :  integer, window length\n",
    "        thrshd   :  float,  determine if an activity is strong enough inside a window\n",
    "        step     :  integer, sliding window by step\n",
    "    \"\"\"\n",
    "    print('Starting Extract CSI for Label {}'.format(label))\n",
    "    label = label.lower()\n",
    "    if not label in labels:\n",
    "        raise ValueError(\"The label {} should be among 'lie down','fall','bend','run','sitdown','standup','walk'\".format(labels))\n",
    "    \n",
    "    data_path_pattern = os.path.join(raw_folder,label, 'user_*' + label + '*.csv')\n",
    "    input_csv_files = sorted(glob.glob(data_path_pattern))\n",
    "    # annot_csv_files = [os.path.basename(fname).replace('user_', 'annotation_user') for fname in input_csv_files]\n",
    "    # annot_csv_files = [os.path.join(raw_folder, label, fname) for fname in annot_csv_files]\n",
    "    annot_csv_files = os.path.join(raw_folder,label, 'Annotation_user_*' + label + '*.csv')\n",
    "    annot_csv_files = sorted(glob.glob(annot_csv_files))\n",
    "    feature = []\n",
    "    index = 0\n",
    "    for csi_file, label_file in zip(input_csv_files, annot_csv_files):\n",
    "        index += 1\n",
    "        if not os.path.exists(label_file):\n",
    "            print('Warning! Label File {} doesn\\'t exist.'.format(label_file))\n",
    "            continue\n",
    "        feature.append(merge_csi_label(csi_file, label_file, win_len=win_len, thrshd=thrshd, step=step))\n",
    "        print('Finished {:.2f}% for Label {}'.format(index / len(input_csv_files) * 100,label))\n",
    "    \n",
    "    feat_arr = np.concatenate(feature, axis=0)\n",
    "    if save:\n",
    "        np.savez_compressed(\"X_{}_win_{}_thrshd_{}percent_step_{}.npz\".format(\n",
    "            label, win_len, int(thrshd*100), step), feat_arr)\n",
    "    # one hot\n",
    "    feat_label = np.zeros((feat_arr.shape[0], len(labels)))\n",
    "    feat_label[:, labels.index(label)] = 1\n",
    "    return feat_arr, feat_label\n",
    "\n",
    "\n",
    "def train_valid_split(numpy_tuple, train_portion=0.75, seed=379):\n",
    "    \"\"\"\n",
    "    Returns Train and Valid Datset with the format of (x_train, y_train, x_valid, y_valid),\n",
    "    where x_train and y_train are shuffled randomly.\n",
    "\n",
    "    Args:\n",
    "        numpy_tuple  : tuple of numpy array: (x_lie_down, x_fall, x_bend, x_run, x_sitdown, x_standup, x_walk)\n",
    "        train_portion: float, range (0,1)\n",
    "        seed         : random seed\n",
    "    \"\"\"\n",
    "    np.random.seed(seed=seed)\n",
    "    x_train = []\n",
    "    x_valid = []\n",
    "    y_valid = []\n",
    "    y_train = []\n",
    "\n",
    "    for i, x_arr in enumerate(numpy_tuple):\n",
    "        index = np.random.permutation([i for i in range(x_arr.shape[0])])\n",
    "        split_len = int(train_portion * x_arr.shape[0])\n",
    "        x_train.append(x_arr[index[:split_len], ...])\n",
    "        tmpy = np.zeros((split_len,7))\n",
    "        tmpy[:, i] = 1\n",
    "        y_train.append(tmpy)\n",
    "        x_valid.append(x_arr[index[split_len:],...])\n",
    "        tmpy = np.zeros((x_arr.shape[0]-split_len,7))\n",
    "        tmpy[:, i] = 1\n",
    "        y_valid.append(tmpy)\n",
    "    \n",
    "    x_train = np.concatenate(x_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    x_valid = np.concatenate(x_valid, axis=0)\n",
    "    y_valid = np.concatenate(y_valid, axis=0)\n",
    "\n",
    "    index = np.random.permutation([i for i in range(x_train.shape[0])])\n",
    "    x_train = x_train[index, ...]\n",
    "    y_train = y_train[index, ...]\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "    \n",
    "    \n",
    "\n",
    "def extract_csi(raw_folder, labels, save=False, win_len=500, thrshd=0.6, step=50):\n",
    "    \"\"\"\n",
    "    Return List of Array in the format of [X_label1, y_label1, X_label2, y_label2, .... X_Label7, y_label7]\n",
    "    Args:\n",
    "        raw_folder: the folder path of raw CSI csv files\n",
    "        labels    : all the labels existing in the folder\n",
    "        save      : boolean, choose whether save the numpy array \n",
    "        win_len   :  integer, window length\n",
    "        thrshd    :  float,  determine if an activity is strong enough inside a window\n",
    "        step      :  integer, sliding window by step\n",
    "    \"\"\"\n",
    "    ans = []\n",
    "    for label in labels:\n",
    "        feature_arr, label_arr = extract_csi_by_label(raw_folder, label, labels, save, win_len, thrshd, step)\n",
    "        ans.append(feature_arr)\n",
    "        ans.append(label_arr)\n",
    "    return tuple(ans)\n",
    "\n",
    "\n",
    "class AttenLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Attention Layers used to Compute Weighted Features along Time axis\n",
    "    Args:\n",
    "        num_state :  number of hidden Attention state\n",
    "    \n",
    "    edited code provided on https://github.com/ludlows\n",
    "    \"\"\"\n",
    "    def __init__(self, num_state, **kw):\n",
    "        super(AttenLayer, self).__init__(**kw)\n",
    "        self.num_state = num_state\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight('kernel', shape=[input_shape[-1], self.num_state])\n",
    "        self.bias = self.add_weight('bias', shape=[self.num_state])\n",
    "        self.prob_kernel = self.add_weight('prob_kernel', shape=[self.num_state])\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        atten_state = tf.tanh(tf.tensordot(input_tensor, self.kernel, axes=1) + self.bias)\n",
    "        logits = tf.tensordot(atten_state, self.prob_kernel, axes=1)\n",
    "        prob = tf.nn.softmax(logits)\n",
    "        weighted_feature = tf.reduce_sum(tf.multiply(input_tensor, tf.expand_dims(prob, -1)), axis=1)\n",
    "        return weighted_feature\n",
    "    \n",
    "    # for saving the model\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_state': self.num_state,})\n",
    "        return config\n",
    "\n",
    "\n",
    "class CSIModelConfig:\n",
    "    \"\"\"\n",
    "    class for Human Activity Recognition (\"lie down\", \"fall\", \"bend\", \"run\", \"sitdown\", \"standup\", \"walk\")\n",
    "    Using CSI (Channel State Information)\n",
    "\n",
    "    Args:\n",
    "        win_len   :  integer (500 default) window length for batching sequence\n",
    "        step      :  integer (200  default) sliding window by this step\n",
    "        thrshd    :  float   (0.6  default) used to check if the activity is intensive inside a window\n",
    "        downsample:  integer >=1 (2 default) downsample along the time axis\n",
    "    \"\"\"\n",
    "    def __init__(self, win_len=500, step=50, thrshd=0.6, downsample=1):\n",
    "        self._win_len = win_len\n",
    "        self._step = step\n",
    "        self._thrshd = thrshd\n",
    "        self._labels = (\"lie down\", \"fall\", \"bend\", \"run\", \"sitdown\", \"standup\", \"walk\")\n",
    "        self._downsample = downsample\n",
    "\n",
    "    def preprocessing(self, raw_folder, save=False):\n",
    "        \"\"\"\n",
    "        Returns the Numpy Array for training within the format of (X_lable1, y_label1, ...., X_label7, y_label7)\n",
    "        Args:\n",
    "            raw_folder: the folder containing raw CSI \n",
    "            save      : choose if save the numpy array\n",
    "        \"\"\"\n",
    "        numpy_tuple = extract_csi(raw_folder, self._labels, save, self._win_len, self._thrshd, self._step)\n",
    "        if self._downsample > 1:\n",
    "            return tuple([v[:, ::self._downsample,...] if i%2 ==0 else v for i, v in enumerate(numpy_tuple)])\n",
    "        return numpy_tuple\n",
    "    \n",
    "    def load_csi_data_from_files(self, np_files):\n",
    "        \"\"\"\n",
    "        Returns the Numpy Array for training within the format of (X_lable1, y_label1, ...., X_label7, y_label7)\n",
    "        Args:\n",
    "            np_files: ('x_lie_down.npz', 'x_fall.npz', 'x_bend.npz', 'x_run.npz', 'x_sitdown.npz', 'x_standup.npz', 'x_walk.npz')\n",
    "        \"\"\"\n",
    "        if len(np_files) != 7:\n",
    "            raise ValueError('There should be 7 numpy files for lie down, fall, bend, run, sitdown, standup, walk.')\n",
    "        x = [np.load(f)['arr_0'] for f in np_files]\n",
    "        if self._downsample > 1:\n",
    "            x = [arr[:,::self._downsample, :] for arr in x]\n",
    "        y = [np.zeros((arr.shape[0], len(self._labels))) for arr in x]\n",
    "        numpy_list = []\n",
    "        for i in range(len(self._labels)):\n",
    "            y[i][:,i] = 1\n",
    "            numpy_list.append(x[i])\n",
    "            numpy_list.append(y[i])\n",
    "        return tuple(numpy_list)\n",
    "\n",
    "\n",
    "    \n",
    "    def build_model(self, n_unit_lstm=200, n_unit_atten=400):\n",
    "        \"\"\"\n",
    "        Returns the Tensorflow Model which uses AttenLayer\n",
    "        \"\"\"\n",
    "        if self._downsample > 1:\n",
    "            length = len(np.ones((self._win_len,))[::self._downsample])\n",
    "            x_in = tf.keras.Input(shape=(length, 52))\n",
    "        else:\n",
    "            x_in = tf.keras.Input(shape=(self._win_len, 52))\n",
    "        x_tensor = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=n_unit_lstm, return_sequences=True))(x_in)\n",
    "        x_tensor = AttenLayer(n_unit_atten)(x_tensor)\n",
    "        pred = tf.keras.layers.Dense(len(self._labels), activation='softmax')(x_tensor)\n",
    "        model = tf.keras.Model(inputs=x_in, outputs=pred)\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load_model(hdf5path):\n",
    "        \"\"\"\n",
    "        Returns the Tensorflow Model for AttenLayer\n",
    "        Args:\n",
    "            hdf5path: str, the model file path\n",
    "        \"\"\"\n",
    "        model = tf.keras.models.load_model(hdf5path, custom_objects={'AttenLayer':AttenLayer})\n",
    "        return model\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Error! Correct Command: python3 csimodel.py Dataset_folder_path\")\n",
    "    raw_data_folder = sys.argv[0]\n",
    "\n",
    "    # preprocessing\n",
    "    cfg = CSIModelConfig(win_len=500, step=50, thrshd=0.6, downsample=1)\n",
    "    numpy_tuple = cfg.preprocessing('CSV/', save=True)\n",
    "    # load previous saved numpy files, ignore this if you haven't saved numpy array to files before\n",
    "    # numpy_tuple = cfg.load_csi_data_from_files(('x_lie_down.npz', 'x_fall.npz', 'x_bend.npz', 'x_run.npz', 'x_sitdown.npz', 'x_standup.npz', 'x_walk.npz'))\n",
    "    x_lie_down, y_lie_down, x_fall, y_fall, x_bend, y_bend, x_run, y_run, x_sitdown, y_sitdown, x_standup, y_standup, x_walk, y_walk = numpy_tuple\n",
    "    x_train, y_train, x_valid, y_valid = train_valid_split(\n",
    "        (x_lie_down, x_fall, x_bend, x_run, x_sitdown, x_standup, x_walk),\n",
    "        train_portion=0.75, seed=379)\n",
    "    # parameters for Deep Learning Model\n",
    "    model = cfg.build_model(n_unit_lstm=200, n_unit_atten=400)\n",
    "    # train\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    history=model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=128, epochs=200,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ModelCheckpoint('best_atten.hdf5',\n",
    "                                                monitor='val_accuracy',\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=False)\n",
    "            ])\n",
    "\n",
    "\n",
    "    \n",
    "    # load the best model    \n",
    "    model = cfg.load_model('best_atten.hdf5')\n",
    "    y_pred = model.predict(x_valid)\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix , ConfusionMatrixDisplay\n",
    "    import matplotlib.pyplot as plt\n",
    "    cm=confusion_matrix(np.argmax(y_valid, axis=1), np.argmax(y_pred, axis=1))\n",
    "    cm= cm.astype('float')/ cm.sum(axis=1)[:, np.newaxis]\n",
    "    cmd=ConfusionMatrixDisplay(cm, display_labels=[\"lie down\", \"fall\", \"bend\", \"run\", \"sitdown\", \"standup\", \"walk\"])\n",
    "    plt.figure(figsize=(40,40))\n",
    "\n",
    "    # print(cm)\n",
    "    cmd.plot()\n",
    "    plt.title('confusion matrix')\n",
    "    plt.ylabel('y_valid')\n",
    "    plt.xlabel('y_pred')\n",
    "    plt.savefig('confusion matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "    #plot curves\n",
    "    import matplotlib.pyplot as plt\n",
    "    accuracy=history.history['accuracy']\n",
    "    val_accuracy=history.history['val_accuracy']\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('model accuracy.png')    \n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('model loss.png')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    te = open('log.txt','w')  # File where you need to keep the logs\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
